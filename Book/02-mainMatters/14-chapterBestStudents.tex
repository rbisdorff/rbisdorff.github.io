\chapter{The best students, where do they study? A rating case study}
\label{sec:14}

\abstract*{ In 2004, the German magazine \emph{Der Spiegel}, with the help of \emph{McKinsey \& Company} and \emph{AOL}, conducted an extensive online survey, assessing the apparent quality of German University students \citep{SPI-2004}. The eventually published results by the \emph{Spiegel} magazine concerned nearly 50,000 students, enrolled in one of fifteen popular academic subjects, like \emph{German Studies}, \emph{Life Sciences}, \emph{Psychology}, \emph{Law}  or \emph{CS}. Based on this published data, we present and discuss in this chapter, how to \emph{rate} with the help of our \Digraph software ressources the apparent global \emph{enrolment quality} of new performance records.}

\abstract{ In 2004, the German magazine \emph{Der Spiegel}, with the help of \emph{McKinsey \& Company} and \emph{AOL}, conducted an extensive online survey, assessing the apparent quality of German University students. The eventually published results by the \emph{Spiegel} magazine concerned nearly 50,000 students, enrolled in one of fifteen popular academic subjects, like \emph{German Studies}, \emph{Life Sciences}, \emph{Psychology}, \emph{Law}  or \emph{CS}. Based on this published data, we present and discuss in this chapter, how to \emph{rate} with the help of our \Digraph software ressources the apparent global \emph{enrolment quality} of new performance records.}

\section{The rating problem}
\label{sec:14.1}

In the 2004 \Spiegel survey, more than 80,000 students, by participating, were questioned on their '\emph{Abitur}' and university exams' marks, time of studies and age, grants, awards and publications, IT proficiency, linguistic skills, practical work experience, foreign mobility and civil engagement. Each student received in return a quality score through a specific weighing of the collected data which depended on the subject the student is mainly studying. Publishing only those subject-University combinations, where at least 18 students had correctly filled in the questionnaire, left 41 German Universities where, for at least eight out of the fifteen subjects, an average enrolment quality score could be determined  \citep{SPI-2004,SPI-2004m}.

We suppose in this rating case study that five German universities: \texttt{U1}, \texttt{U2}, \texttt{U3}, \texttt{U4} and \texttt{U5} conducted in 2005 a similar survey among their enrolled students which gave the following enrolment quality scores per academic subject:
\begin{table}[ht]
\caption{Enrolment quality scores per academic scores}
\label{tab:14.1}       % Give a unique label
\begin{center}
  %\begin{small}
    \begin{tabular}{l|c|c|c|c|c}
      \svhline\noalign{\smallskip}
      Subject & U1 & U2 & U3 & U4 & U5 \\
      \noalign{\smallskip}\hline\noalign{\smallskip}
      \texttt{bio}   & NA     & 53.10 & 49.70 & 52.20 & 55.20\\
      \texttt{med}   & NA     & NA    & NA    & 49.50 & 55.50\\
      \              & \      & \     & \     & \     & \    \\
      \texttt{math}  & 56.80  & 54.70 & 56.30 & 58.60 & 61.30\\
      \texttt{phys}  & 58.90  & 59.80 & 53.90 & 59.10 & 60.90\\
      \texttt{chem}  & 52.00  & 50.10 & 54.20 & 53.60 & 56.70\\
      \              & \      & \     & \     & \     & \    \\
      \texttt{germ}  & 51.40  & 53.50 & 51.40 & 53.30 & 61.40\\
      \texttt{pol}   & NA     & 54.00 & NA    & 50.80 & 59.60\\
      \texttt{soc}   & 59.10  & 51.50 & 55.60 & 51.00 & 52.20\\
      \texttt{psy}   & 57.70  & NA    & 54.40 & 62.70 & 59.80\\
      \              & \      & \     & \     & \     & \    \\
      \texttt{law}   & NA     & NA    & 41.90 & NA    & 51.10\\
      \texttt{eco}   & 49.60  & NA    & NA    & NA    & 54.40\\
      \texttt{mgt}   & 54.00  & 53.40 & 50.70 & 49.60 & NA   \\
      \              & \      & \     & \     & \     & \    \\
      \texttt{info}  & 55.40  & 52.60 & 55.80 & 54.60 & NA   \\ 
      \texttt{elec}  & 56.10  & 54.50 & NA    & 57.20 & NA   \\
      \texttt{mec}   & 54.30  & 55.20 & NA    & 54.40 & NA   \\
      \noalign{\smallskip}\hline
    \end{tabular}
  %\end{small}
\end{center}
\end{table}

In Table~\vref{tab:14.1}, the fifteen popular academic subjects are grouped into topical 'Faculties': - \emph{Humanities}; - \emph{Law, Economics \& Management}; - \emph{Life Sciences \& Medicine}; - \emph{Natural Sciences \& Mathematics}; and - \emph{Technology}. None of the five universities has students enrolled in all the fifteen subjects. University U1 has, for instance, no students in Life Sciences \& Medicine, and in Law and Politology. Whereas the University U5 does not offer any Technology subjects.

The average enrolment quality scores of the five universities, shown in Table~\vref{tab:14.1} are stored in a file named \texttt{ratingCaseStudy.py} of \texttt{PerformanceTableau} format. The \texttt{showHTMLPerformanceTableau()}  method produces in Figure~\vref{fig:14.1} a colourful browser view of these performance records. 
\begin{lstlisting}
>>> from perfTabs import PerformanceTableau
>>> pt = PerformanceTableau('ratingCaseStudy')
>>> pt.showHTMLPerformanceTableau(Transposed=True,\
...                     title='Average enrolment scores')
\end{lstlisting}
\begin{figure}[ht]
\sidecaption[t]
\includegraphics[width=7cm]{Figures/14-1-enrolmentScores.png}
\caption[Student enrolment quality scores per subject]{Student enrolment quality scores per subject. The light green, resp. light red, figures indicate highest, resp. lowest, score among the five universities.}
\label{fig:14.1}       % Give a unique label
\end{figure}

With the best score in nine out of fifteen subjects, university \texttt{U5} presents the highest global enrolment quality of the five, whereas university \texttt{U3}, with five lowest scores, shows the lowest student enrolment quality of the five.

The university administrations would like to know now how their respective enrolment quality scores are to be appreciated in view the results of the 2004 \Spiegel survey. Are they among the top universities, the midfield or the bottom group?

\section{The 2004 performance quintiles}
\label{sec:14.2}

The estimated lower-closed performance quintiles of the 2004 average enrolment quality per academic subject are stored in a file named \texttt{historicalQuan\-tiles.py}\footnote{The file may be found in the \texttt{examples} directory of the \Digraph resources.} which can be reloaded with the \texttt{PerformanceQuantiles} class.\index{PerformanceQuantiles@\texttt{PerformanceQuantiles} class}.
\begin{lstlisting}[caption={Inspecting stored historical performance quantiles},label=list:14.1]
>>> from performanceQuantiles import PerformanceQuantiles
>>> pq = PerformanceQuantiles('historicalQuintiles')
>>> pq
  *---- PerformanceQuantiles instance description ---*
   Instance class   : PerformanceQuantiles
   Instance name    : historicalQuintiles
   Objectives       : 4
   Criteria         : 15
   Quantiles        : 5
   History sizes    : {'germ': 39, 'pol': 34, 'psy': 34,
                       'soc': 32, 'law': 32, 'eco': 21,
                       'mgt': 34, 'bio': 34, 'med': 28,
                       'phys': 37, 'chem': 35, 'math': 27,
                       'info': 33, 'elec': 14, 'mec': 13}
   Attributes       : ['name', 'objectives', 'NA', 'criteria',
                       'quantilesFrequencies', 'historySizes',
                       'LowerClosed', 'limitingQuantiles',
                       'cdf', 'perfTabType']
\end{lstlisting}

The history sizes, reported in Listing~\vref{list:14.1}, indicate the number of Universities evaluated in the 2004 survey in each one of the popular fifteen subjects. \emph{German Studies}, for instance, were evaluated for 39 out of 41 Universities, whereas \emph{Electrical} and \emph{Mechanical Engineering} were only evaluated for 14, respectively 13 Institutions. None of the fifteen subjects were evaluated in all the 41 Universities \footnote{It would have been interesting to estimate such quantile limits from the individual quality scores of all the nearly 50,000 surveyed students. But this data was not public \citep{SPI-2004}.}.                      

Details of the fifteen academic subjects --the performance criteria-- may be consulted in a browser view (see Fig.~\vref{fig:14.2}).
\begin{lstlisting}
>>> pt.showHTMLCriteria()
\end{lstlisting}
\begin{figure}[ht]
%\sidecaption
\includegraphics[width=\hsize]{Figures/14-2-spiegelCriteria.png}
\caption[Fifteen popular academic subjects]{The fifteen academic subjects taken into account for assessing the student enrolment quality}
\label{fig:14.2}       % Give a unique label
\end{figure}

All fifteen subjects are considered equally significant (see Column Weight). The average scores in most subjects vary from 45 to 65. In some subjects, however, like \emph{Law Studies} ($35.0 - 65-0$) and \emph{Politology} ($50.0 - 70.0$) a different variability is observed. The average enrolment scores per subject are hence incommensurable and global average enrolment scores over all subjects become meaningless. 

To take furthermore into account the potential and very likely imprecision of the quality scores' computation, we assume that, for all subjects, an average enrolment quality score difference of $0.1$ is \emph{insignificant}, whereas a difference of $0.5$ is sufficient to positively attest a \emph{better} enrolment quality. No considerable performance difference are assumed.

The \texttt{showLimitingQuantiles()} method prints in Listing~\vref{list:14.2} the estimated quintile limits of the 2004 survey.
\begin{lstlisting}[caption={Estimated quintile limits of the 2004 survey},label=list:14.2,basicstyle=\ttfamily\scriptsize]
>>> pq.showLimitingQuantiles()
  *----  performance quantiles -----*
  criteria | weights |  '0.00'  '0.20'  '0.40'  '0.60'  '0.80'  '1.00'   
  ---------|----------------------------------------------------------
   'bio'   |   1.0   |   45.00   50.40   51.80   53.14   55.04   57.10  
   'chem'  |   1.0   |   45.00   53.30   54.20   55.80   57.40   58.80  
   'eco'   |   1.0   |   49.60   52.14   53.38   54.28   56.94   60.80  
   'elec'  |   1.0   |   50.10   54.08   55.34   56.54   57.64   60.20  
   'germ'  |   1.0   |   45.00   52.14   54.02   55.84   57.48   61.40  
   'info'  |   1.0   |   45.00   54.40   55.44   56.68   58.10   59.80  
   'law'   |   1.0   |   39.10   42.30   45.08   46.30   47.26   51.10  
   'math'  |   1.0   |   51.60   56.54   57.76   59.44   61.00   63.10  
   'mec'   |   1.0   |   51.90   54.02   54.48   55.18   56.54   57.80  
   'med'   |   1.0   |   45.00   49.20   49.84   51.10   52.42   60.10  
   'mgt'   |   1.0   |   47.50   52.16   52.98   54.68   55.96   68.00  
   'phys'  |   1.0   |   53.90   58.78   59.90   60.96   61.96   62.80  
   'pol'   |   1.0   |   50.80   54.62   56.18   57.78   59.78   65.90  
   'psy'   |   1.0   |   52.50   57.58   58.46   59.80   60.94   64.10  
   'soc'   |   1.0   |   45.00   51.70   53.92   55.42   56.26   59.80  
\end{lstlisting}
                     
We see confirmed again the incommensurability between the subjects, we noticed already in the apparent enrolment quality scoring, especially between \emph{Law Studies} ($39.1 - 51.1$) and \emph{Politology} ($50.5 - 65.9$). \footnote{The \emph{Spiegel} authors opted therefore for a simple 3-tiling of the Universities per evaluated academic subject, followed by an average \Borda scores based global ranking \citep{SPI-2004}.}


\section{Rating-by-ranking with lower-closed quintile limits}
\label{sec:14.3}


We add, now, the estimated quintile limits to the enrolment quality records of the 5 Universities and rank, by using the \Copeland rule, all these records conjointly together with the help of the \texttt{LearnedQuantilesRatingDigraph} class\index{LearnedQuantilesRatingDigraph@\texttt{LearnedQuantilesRatingDigraph} class} from the \texttt{sortingDigraphs} module\index{sortingDigraphs@\texttt{sortingDigraphs} module}.
\begin{lstlisting}
>>> from sortingDigraphs import\
...                 LearnedQuantilesRatingDigraph
>>> lqr = LearnedQuantilesRatingDigraph(pq,pt,\
...                 rankingRule='Copeland')
>>> lqr
  *-----  Object instance description -----------*
   Instance class      : LearnedQuantilesRatingDigraph
   Instance name       : learnedRatingDigraph
   Criteria            : 15
   Quantiles           : 5
   Lower-closed bins   : True
   New actions         : 5
   Size                : 44
   Determinateness (%) : 77.6
   Ranking rule        : Copeland
   Ordinal correlation : +0.97
\end{lstlisting}

The resulting ranking of the 5 Universities including the lower-closed quintile score limits may be well illustrated  with the \texttt{showHTMLRatingHeatmap()} method.\index{showHTMLRatingHeatmap@\texttt{showHTMLRatingHeatmap()}}
\begin{lstlisting}
>>> lqr.showHTMLRatingHeatmap(colorLevels=5,\
...              Correlations=True,\
...              ndigits=1,rankingRule='Copeland')
\end{lstlisting}
\begin{figure}[ht]
% %\sidecaption
\includegraphics[width=\hsize]{Figures/14-3-quintilingResult.png}
\caption{Heatmap view of the quintiles rating-by-ranking result}
\label{fig:14.3}       % Give a unique label
\end{figure}

The ordinal correlation ($+0.97$) of the \Copeland ranking with the underlying bipolar-valued outranking digraph is very high (see Fig.~\vref{fig:14.3} Row 1). Most correlated subjects with this \emph{rating-by-ranking} result appear to be \emph{Physics} ($+0.79$), \emph{Mathematics} ($+0.77$) and \texttt{German Studies} ($+0.77$). \emph{Sociology} ($+0.36$) is the less correlated subjects (see Row 4).

From the actual ranking position of the lower 5-tiling limits, we may now immediately deduce the quintile enrolment quality equivalence classes. No university reaches the highest quintile ($[0.80 - [$), whereas \texttt{U3} is rated into the lowest quintile ($[0.00- 0.20[$). The other three universities U1, U2 and U4 are rated in the second quintile ($[0.20- 0.40[$). The rating result may be easily printed out with the \texttt{showQuantilesRating()} method\index{showQuantilesRating@\texttt{showQuantilesRating()}}.
\begin{lstlisting}[caption={Showing the quintiling of the enrolment quality of the 5 Universities},label=list:14.3]
>>> lqr.showQuantilesRating()
  *---- Quantiles rating result ----*
   [0.60 - 0.80[ ['U5']
   [0.20 - 0.40[ ['U1', 'U4', 'U2']
   [0.00 - 0.20[ ['U3']
\end{lstlisting}

A corresponding \emph{graphviz} drawing with the special \texttt{exportRatingByRan\-kingGraphViz()} method\index{exportRatingByRankingGraphViz@\texttt{exportRatingByRankingGraphViz()}} may well illustrate in Figure~\vref{fig:14.4} these enrolment quality equivalence classes.
\begin{lstlisting}
>>> lqr.exportRatingByRankingGraphViz('ratingResult')
  *---- exporting a dot file for GraphViz tools ---------*
   Exporting to ratingResult.dot
   dot -Grankdir=TB -Tpdf dot -o ratingResult.png
\end{lstlisting}
\begin{figure}[ht]
\sidecaption[t]
\includegraphics[width=4cm]{Figures/14-4-ratingResult.pdf}
\caption{Drawing of the quintiles rating-by-ranking result}
\label{fig:14.4}       % Give a unique label
\end{figure}
% \clearpage 

We have noticed in Chapter~\ref{sec:8}, that there is not a unique optimal rule for ranking from a given outranking digraph like digraph \texttt{lqr} here. The \Copeland rule, for instance, has the advantage of being \Condorcet consistent, i.e. when the outranking digraph models a linear ranking, this ranking will necessarily be the result of the \Copeland rule. When this is not the case, and especially when the outranking digraph shows chordless circuits, all potential ranking rules may give very divergent ranking results, and sometimes substantially divergent rating-by-ranking results. The \texttt{computeChordlessCircuits()} and \texttt{showChordlessCircuits()} methods allow to check this issue \footnote{The \texttt{computeChordlessCircuits()} and \texttt{showChordlessCircuits()} methods are separate because there are various methods available for enumerating the chordless circuits in a digraph \citep{BIS-2010}.}.
\begin{lstlisting}
>>> lqr.computeChordlessCircuits()
>>> lqr.showChordlessCircuits()
*---- Chordless circuits ----*
1 circuits.
1:  ['U1', 'U2', 'U4'] , credibility : 0.200
\end{lstlisting}

Indeed, there appears an outranking circuit among the three universities \texttt{U1}, \texttt{U2} and \texttt{U4} rated into the 2nd quintile. It is, hence, interesting, to verify if the epistemic fusion of the rating-by-ranking results, one may obtain when applying three different ranking rules, like the \Kemeny, \Copeland and \NetFlows rules, does actually confirm our rating-by-ranking result shown in Figure~\vref{fig:14.4}. For this purpose we make use in Listing~\vref{list:14.4} of the \texttt{RankingsFusionDigraph} class \index{RankingsFusionDigraph@\texttt{RankingsFusionDigraph} class}.
\begin{lstlisting}[caption={Computing the epistemic fusion of two rating-by-rankig results},label=list:14.4]
>>> # lqr.actionsRanking is Copeland ranked
>>> from linearOrders import KemenyOrder,\
...                          NetFlowsOrder
>>> ke = KemenyOrder(lqr,orderLimit=10)
>>> nf = NetFlowsOrder(lqr)
>>> from transitiveDigraphs import\
...                RankingsFusionDigraph
>>> rankings = [lqr.actionsRanking,\
...             nf.netFlowsRanking,\
...             ke.kemenyRanking]
>>> rankings
 [['m5','u5','m4','m3','u1','u2','u4','m2','u3','m1'],
  ['m5','u5','m4','m3','u1','u4','u2','u3','m2','m1'],
  ['m5','u5','m4','m3','u1','u4','u2','m2','u3','m1']]
>>> rf = RankingsFusionDigraph(lqr,rankings)
>>> rf.exportGraphViz(fileName='fusionResult',\
...           WithRatingDecoration=True)
exporting a dot file for GraphViz tools
Exporting to fusionResult.dot
dot -Grankdir=TB -Tpng fusionResult.dot\
                 -o fusionResult.png
\end{lstlisting}
\begin{figure}[ht]
\sidecaption[t]
\includegraphics[width=4cm]{Figures/14-5-fusionResult.pdf}
\caption[Disjunctive fusion of the \Kemeny, \Copeland and \NetFlows rankings]{Disjunctive fusion of the \Kemeny, \Copeland and \NetFlows rankings. They diverge in their rating-by-ranking of Universities \texttt{U2}, \texttt{U3} and \texttt{U4}}
\label{fig:14.5}       % Give a unique label
\end{figure}

The fusion of the three rating-by-ranking results is shown in Figure~\vref{fig:14.5} where we see that they diverge solely in their rating-by-ranking of Universities \texttt{U2}, \texttt{U3} and \texttt{U4}. In Listing~\vref{list:14.5} Lines 12-14, one may more precisely notice that the \Kemeny and \Copeland rules rate \texttt{U3} in the first quintile ($[0.00- 0.20[$), whereas the \NetFlows rule puts \texttt{U3} together with \texttt{U1}, \texttt{U2} and \texttt{U4} into the second quintile ($[0.20- 0.40[$). And, the \Kemeny rule inverts the position of \texttt{U2} and \texttt{U4}.

In Listing~\vref{list:14.5}, the \texttt{showRankingConsensusQuality()} method\index{showRankingConsensusQuality@\texttt{showRankingConsensusQua\-lity()}} reveals finally how fair \Kemeny and \Copeland rules actually balance the fifteen academic subjects. 
\begin{lstlisting}[caption={Checking the consensus quality of \Kemeny and \Copeland rankings},label=list:14.5,basicstyle=\ttfamily\scriptsize]
>>> lqr.showRankingConsensusQuality(ke.kemenyRanking)
Consensus quality of ranking:
['m5', 'u5', 'm4', 'm3', 'u1', 'u2', 'u4', 'm2', 'u3', 'm1']
criterion (weight): correlation
-------------------------------
phys (0.067): +0.833
germ (0.067): +0.789
math (0.067): +0.722
bio (0.067): +0.667
mgt (0.067): +0.633
chem (0.067): +0.611
psy (0.067): +0.544
pol (0.067): +0.500
info (0.067): +0.478
mec (0.067): +0.422
law (0.067): +0.411
soc (0.067): +0.400
med (0.067): +0.400
eco (0.067): +0.389
elec (0.067): +0.367
Summary:
Weighted mean marginal correlation (a): +0.544
Standard deviation (b)                : +0.150
Ranking fairness (a)-(b)              : +0.394
>>> lqr.showRankingConsensusQuality(lqr.actionsRanking)
Consensus quality of ranking:
['m5', 'u5', 'm4', 'm3', 'u1', 'u4', 'u2', 'm2', 'u3', 'm1']
criterion (weight): correlation
-------------------------------
phys (0.067): +0.789
math (0.067): +0.767
germ (0.067): +0.767
chem (0.067): +0.656
bio (0.067): +0.622
mgt (0.067): +0.589
psy (0.067): +0.544
info (0.067): +0.522
pol (0.067): +0.456
law (0.067): +0.411
elec (0.067): +0.411
med (0.067): +0.400
eco (0.067): +0.389
mec (0.067): +0.378
soc (0.067): +0.356
Summary:
Weighted mean marginal correlation (a): +0.537
Standard deviation (b)                : +0.148
Ranking fairness (a)-(b)              : +0.389
\end{lstlisting}

The consensus quality of the two rating-by-ranking results do not sensibly differ one from the other. They both show a similar high mean marginal correlation $(+0.544, +0.537)$, similar standard deviations $(+0.150, +0.148)$ and, hence a similar ranking fairness $(+0.394, +0.389)$. 

To furthermore check the quality of our \Copeland rating-by-ranking result, we shall below compute a direct rating-by-sorting into the historic 2004 quintiles of the enrolment quality scores, without making use of any outranking digraph based ranking rule.

\section{Rating by quintiles sorting}
\label{sec:14.4}

In the case study here, the five Universities \texttt{U1}, \texttt{U2}, \texttt{U3}, \texttt{U4} and \texttt{U5} represent the decision actions: \emph{where to study}. We say now that University $x$ is sorted into the lower-closed quintile $k$ when the performance record of $x$ positively outranks the lower limit record $\mathbf{q}(p_{k-1}$ of quintile $q$ and $x$ does not positively outrank the upper limit record $\mathbf{q}(p_{k}$ of quintile $q$, for $q = 1,...5$ (see List.~\vref{list:14.1}).

With the help of the bipolar-valued characteristic of the outranking relation $r(x \succsim y)$ we may indeed compute the bipolar-valued characteristic of the assertion: ``$x$ \emph{belongs to the lower-closed quintile class} $\mathbf{q}_k$'':
\begin{equation}\label{eq:14.1}
r(x \in \mathbf{q}_k) \; = \; \min \big[ r\big(x \succsim \mathbf{q}(p_{k-1})\big),\, r\big(x \not\succsim \mathbf{q}(p_{k})\big)\big]
\end{equation}
where $k = 1,...5$ and $(p_{k})$ denote the respective quintile proportions: $0.20$, $0.40$, $0.60$, $0.80$ and $1.00$. As bipolar-valued outranking digraphs verify the coduality principle, $r\big(x \not\succsim \mathbf{q}(p_{k}) \big) = r\big(x precnsim \mathbf{q}(p_{k})$ (see Sec.~\ref{sec:9.2}).

The \texttt{showSortingCharacteristics()} method\index{showSortingCharacteristics@\texttt{showSortingCharacteristics()}} gives a precise look in Listing~\vref{list:14.6} on these quintiles sorting characteristics.
\begin{lstlisting}[caption={Showing quantiles sorting characteristics},label=list:14.6,basicstyle=\ttfamily\scriptsize]
>>> lqr.showSortingCharacteristics()
x  in  K_k	     r(x >= m_k)     r(x < M_k)	    r(x in K_k)
U5 in [0.00 - 0.20[	 0.73		 -0.73		 -0.73
U5 in [0.20 - 0.40[	 0.73		 -0.60		 -0.60
U5 in [0.40 - 0.60[	 0.60		 -0.60		 -0.60
U5 in [0.60 - 0.80[	 0.60		 0.00		 0.00
U5 in [0.80 - <[	 0.00		 1.00		 0.00

U2 in [0.00 - 0.20[	 0.73		 -0.13		 -0.13
U2 in [0.20 - 0.40[	 0.13		 0.20		 0.13
U2 in [0.40 - 0.60[	 -0.20		 0.47		 -0.20
U2 in [0.60 - 0.80[	 -0.47		 0.73		 -0.47
U2 in [0.80 - <[	 -0.73		 1.00		 -0.73

U4 in [0.00 - 0.20[	 0.87		 -0.47		 -0.47
U4 in [0.20 - 0.40[	 0.47		 0.13		 0.13
U4 in [0.40 - 0.60[	 -0.13		 0.60		 -0.13
U4 in [0.60 - 0.80[	 -0.60		 0.67		 -0.60
U4 in [0.80 - <[	 -0.67		 1.00		 -0.67

U1 in [0.00 - 0.20[	 0.73		 -0.33		 -0.33
U1 in [0.20 - 0.40[	 0.33		 0.13		 0.13
U1 in [0.40 - 0.60[	 -0.13		 0.53		 -0.13
U1 in [0.60 - 0.80[	 -0.53		 0.60		 -0.53
U1 in [0.80 - <[	 -0.60		 1.00		 -0.60

U3 in [0.00 - 0.20[	 0.67		 0.13		 0.13
U3 in [0.20 - 0.40[	 -0.13		 0.27		 -0.13
U3 in [0.40 - 0.60[	 -0.27		 0.53		 -0.27
U3 in [0.60 - 0.80[	 -0.53		 0.67		 -0.53
U3 in [0.80 - <[	 -0.67		 1.00		 -0.67
\end{lstlisting}

The performance record of University U5 cannot be positively rated into a precise quintile, but both the fourth and the fifth quintile are note positively excluded as rating result. Otherwise, the bipolar-valued sorting characteristics verify the rating-by-ranking result we obtained previously with the \Kemeny and \Copeland rating-by-ranking result. 
The \texttt{showActionsSortingResult()} method\index{showActionsSortingResult@\texttt{showActionsSortingResult()}} prints the eventual quintiles rating result:
\begin{lstlisting}[caption={Showing a quintiles rating-by-sorting result},label=list:14.7]
>>> lqr.showActionsSortingResult()
  Quantiles sorting result per decision action
  [0.20 - 0.40[: U1 with credibility: 0.13 = min(0.33,0.13)
  [0.20 - 0.40[: U2 with credibility: 0.13 = min(0.13,0.20)
  [0.00 - 0.20[: U3 with credibility: 0.13 = min(0.67,0.13)
  [0.20 - 0.40[: U4 with credibility: 0.13 = min(0.47,0.13)
  [0.60 - <[: U5 with credibility: 0.60 = min(0.60,1.00)
\end{lstlisting}

The quintiles rating-by-sorting result, shown in Listing~\vref{list:14.7}, confirms the previous \Copeland rating-by-ranking result. However, University \texttt{U5} is here sorted conjointly into the fourth and the fifth quintile, and as such is part of the top rated institutions. A result already convincingly illustrated in the ranked heatmap shown in Figure~\vref{fig:14.3}. 

%\vspace{1cm}
\vspace{\baselineskip}
Let us conclude this hypothetical rating cae study, by saying that we prefer this latter rating-by-sorting approach; perhaps impreciser, due the case given, to missing and contradictory performance data; yet, well grounded in a powerful bipolar-valued logic and epistemic framework. The next Chapter~\ref{sec:15} proposes a series of decision problems suitable for exercises and exam questions.
 
%%%%%%% The chapter bibliography
%\normallatexbib
%\clearpage
%\phantomsection
%\addcontentsline{toc}{section}{Chapter Bibliography}
%\input{02-mainMatters/14-chapterBestStudents.bbl}
\bibliographystyle{spbasic}
\bibliography{03-backMatters/reference}
