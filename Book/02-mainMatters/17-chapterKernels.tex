\chapter{On computing digraph kernels}
\label{sec:17}

\abstract*{ We illustrate in this chapter, first, the concept of graph kernel, i.e. maximal independent set of vertices. In non-symmetric digraphs the kernel concept becomes richer and separates into initial and terminal kernels. In, furthermore, lateralised outranking digraphs, initial and terminal kernels become separate and may deliver suitable first resp. last choice recommendations. After commenting the tractability of kernel computations, we close the chapter with the solving of bipolar-valued kernel equation systems.}

\abstract{We illustrate in this chapter, first, the concept of graph kernel, i.e. maximal independent set of vertices. In non-symmetric digraphs the kernel concept becomes richer and separates into initial and terminal kernels. In, furthermore, lateralised outranking digraphs, initial and terminal kernels become separate and may deliver suitable first resp. last choice recommendations. After commenting the tractability of kernel computations, we close the chapter with the solving of bipolar-valued kernel equation systems.}

\section{What is a graph kernel ?}
\label{sec:17.1}

We call \emph{choice} in a graph, respectively a digraph, a subset of its vertices, resp. of its nodes or actions. A choice $Y$ is called \emph{internally stable}\index{internal stability} or \emph{independent} when there exist no links --(edges) or relations (arcs)-- between its members. Furthermore, a choice $Y$ is called \emph{externally stable}\index{external stability} when for each vertex, node or action $x$ not in $Y$, there exists at least a member $y$ of $Y$ such that $x$ is linked or related to $y$. Now, an internally \emph{and} externally stable choice is called a \emph{kernel}\index{kernel}.  

A first trivial example is immediately given by the maximal independent vertices sets (MISs) of the $n$-cycle graph (see Fig.~\vref{fig:21.5})\index{MIS}. Indeed, each MIS in the $n$-cycle graph is by definition independent, i.e. \emph{internally stable}, and each non selected vertex in the $n$-cycle graph is in relation with either one or even two members of the MIS.

In all graphs or symmetric digraphs, the \emph{maximality condition} imposed on the internal stability is equivalent to the \emph{external stability} condition. Indeed, if there would exist a vertex or node not related to any of the elements of a choice, we may safely add this vertex or node to the given choice without violating its internal stability. All kernels must hence be maximal independent choices\index{maximal independent choice}. In fact, in a topological sense, they correspond to maximal \emph{holes} in the given graph\index{holes}.

Figure~\vref{fig:17.1} illustrates this coincidence between MISs and kernels in graphs and symmetric digraphs with a random 3-regular graph instance generated in Listing~\vref{list:17.1}\index{RandomRegularGraph@\texttt{RandomRegularGraph} class}. A random MIS in this graph may be computed by using the \texttt{MISModel} class\index{MISModel@\texttt{MISModel} class} (see Line~\ref{line:17.1.5} below).
\begin{lstlisting}[caption={Generating a random 3-regular graph of order 12},label=list:17.1]
>>> from graphs import RandomRegularGraph
>>> r3g12 = RandomRegularGraph(order=12,\
...                        degree=3,seed=4)
>>> from graphs import MISModel
>>> mg = MISModel(r3g12)   §\label{line:17.1.5}§
  Iteration:  1
    Running a Gibbs Sampler for 660 step !
    {'a05', 'a07', 'a12'}  is maximal !
>>> mg.exportGraphViz('random3RegularGraph-mis')
  *---- exporting a dot file for GraphViz tools ---*
   Exporting to random3RegularGraph-mis.dot
   fdp -Tpng random3RegularGraph-mis.dot\
                -o random3RegularGraph-mis.png
\end{lstlisting}
\begin{figure}[ht]
\sidecaption[t]
\includegraphics[width=6cm]{Figures/17-1-random3RegularGraph-mis.pdf}
\caption[Coloured MIS in a 3-regular graph]{A random MIS coloured in the random 3-regular graph \texttt{r3g12}. All non blue vertices are covered by a blue vertex}
\label{fig:17.1}       % Give a unique label
\end{figure}

It is easily verified in Figure~\vref{fig:17.1}, that the computed MIS renders indeed a valid kernel of the given graph. The complete set of kernels of this 3-regular graph instance coincides hence with the set of its MISs. 
\begin{lstlisting}[caption={Printing out all maximal independent sets of the random 3-regular graph},label=list:17.2]
>>> g.showMIS()
  *---  Maximal Independent Sets ---*
   ['a05', 'a07', 'a12']
   ['a01', 'a06', 'a08']
   ['a07', 'a08', 'a11']
   ['a01', 'a09', 'a11', 'a12']
   ['a01', 'a02', 'a09', 'a11']
   ['a01', 'a06', 'a09', 'a12']
   ['a01', 'a02', 'a06', 'a09']
   ['a07', 'a09', 'a11', 'a12']
   ['a02', 'a07', 'a09', 'a11']
   ['a06', 'a07', 'a09', 'a12']
   ['a04', 'a06', 'a07', 'a08']
   ['a02', 'a04', 'a05', 'a07']
   ['a04', 'a05', 'a07', 'a08']
   ['a09', 'a10', 'a11', 'a12']
   ['a06', 'a09', 'a10', 'a12']
   ['a04', 'a06', 'a08', 'a10']
   ['a04', 'a06', 'a09', 'a10']
   ['a01', 'a03', 'a11', 'a12']
   ['a01', 'a02', 'a03', 'a11']
   ['a01', 'a03', 'a08', 'a11']
   ['a01', 'a03', 'a05', 'a12']
   ['a01', 'a02', 'a03', 'a05']
   ['a01', 'a03', 'a05', 'a08']
   ['a02', 'a03', 'a04', 'a05']
   ['a03', 'a10', 'a11', 'a12']
   ['a03', 'a08', 'a10', 'a11']
   ['a03', 'a05', 'a10', 'a12']
   ['a02', 'a04', 'a06', 'a07', 'a09']
   ['a03', 'a04', 'a05', 'a08', 'a10']
   number of solutions:  29
   cardinality distribution
   card.:  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]
   freq.:  [0, 0, 0, 3, 24, 2, 0, 0, 0, 0, 0, 0, 0]
   stability number :  5
   execution time: 0.00056 sec.
   Results in self.misset
>>> g.misset
  [frozenset({'a05', 'a07', 'a12'}),
   frozenset({'a11', 'a01', 'a12', 'a09'}),
   frozenset({'a11', 'a01', 'a02', 'a09'}),
    ...
    ...
   frozenset({'a03', 'a10', 'a08', 'a11'}),
   frozenset({'a03', 'a10', 'a12', 'a05'}),
   frozenset({'a03', 'a10', 'a04', 'a05', 'a08'})]
\end{lstlisting}

All graphs and symmetric digraphs admit MISs, hence also kernels. In the context of digraphs, i.e. \emph{oriented} graphs, the kernel concept gets much richer and separates from the symmetric MIS concept.  

\section{Initial and terminal kernels}
\label{sec:17.2}

In an oriented graph context, the internal stability condition of the kernel concept remains untouched; however, the external stability condition gets indeed split up by the orientation into two lateral cases:
\begin{enumerate}[topsep=1pt]
\item A \emph{dominant} stability condition, where each non selected node is dominated by at least one member of the kernel;
\item An \emph{absorbent} stability condition, where each non selected node is absorbed by at least one member of the kernel.
\end{enumerate}

A both internally stable \textbf{and} dominant, resp. absorbent choice is called a dominant or \emph{initial}\index{kernel!initial}, resp. an absorbent or \emph{terminal} kernel\index{kernel!terminal}. From a topological perspective, the initial kernel concept looks from the outside of the digraph into its interior, whereas the terminal kernel looks from the interior of a digraph toward its outside. From an algebraic perspective, the initial kernel is a prefix operand, and the terminal kernel is a postfix operand in the kernel equation systems (see Sec.~\vref{sec:17.6}).

Furthermore, as the kernel concept involves conjointly a positive logical refutation (the internal stability) and a positive logical affirmation (the external stability), it appeared rather quickly necessary in our operational developments to adopt a bipolar characteristic $[-1.0,1.0]$ valuation domain, modelling logical negation by a change of numerical sign and including explicitly a third median value ($0.0$), expressing logical \emph{indeterminateness} --neither positive, nor negative \citep{BIS-2000,BIS-2002,BIS-2004a}.

In such a  bipolar-valued context, we call \emph{prekernel}\index{kernel!prekernel} a choice which is \emph{externally stable} and for which the internal stability condition is \emph{valid or indeterminate}. We say that the independence condition is in this case only \emph{weakly validated}. Notice that all kernels are hence prekernels, but not vice-versa.

In graphs or symmetric digraphs, where there is essentially no apparent \emph{laterality}; all prekernels are initial and terminal at the same time. A universal example is given by the \emph{complete} digraph \index{CompleteDigraph@\texttt{CompleteDigraph} class}.
\begin{lstlisting}[caption={The prekernels of a complete digraph},label=list:17.3]
>>> from digraphs import CompleteDigraph
>>> u = CompleteDigraph(order=5)
>>> u
  *------- Digraph instance description ------*
    Instance class   : CompleteDigraph
    Instance name    : complete
    Digraph Order      : 5
    Digraph Size       : 20
    Valuation domain : [-1.00 ; 1.00]
    ---------------------------------
>>> u.showPreKernels()
  *--- Computing preKernels ---*
   Dominant kernels :
   ['1'] ind. : 1.0; dom. : 1.0; abs. : 1.0
   ['2'] ind. : 1.0; dom. : 1.0; abs. : 1.0
   ['3'] ind. : 1.0; dom. : 1.0; abs. : 1.0
   ['4'] ind. : 1.0; dom. : 1.0; abs. : 1.0
   ['5'] ind. : 1.0; dom. : 1.0; abs. : 1.0
    Absorbent kernels :
   ['1'] ind. : 1.0; dom. : 1.0; abs. : 1.0
   ['2'] ind. : 1.0; dom. : 1.0; abs. : 1.0
   ['3'] ind. : 1.0; dom. : 1.0; abs. : 1.0
   ['4'] ind. : 1.0; dom. : 1.0; abs. : 1.0
   ['5'] ind. : 1.0; dom. : 1.0; abs. : 1.0
  *----- statistics -----
    graph name:  complete
    number of solutions
    dominant kernels :  5
    absorbent kernels:  5
    cardinality frequency distributions
    cardinality     :  [0, 1, 2, 3, 4, 5]
    dominant kernel :  [0, 5, 0, 0, 0, 0]
    absorbent kernel:  [0, 5, 0, 0, 0, 0]
    Execution time  : 0.00004 sec.
    Results in sets: dompreKernels
    and abspreKernels.
\end{lstlisting}

In a complete digraph, each single node is indeed both an initial and a terminal prekernel candidate and there is no definite begin or end of the digraph to be detected. Laterality is here entirely relative to a specific singleton chosen as reference point of view.

The same absence of laterality is apparent (see List.~\vref{list:17.4}) in two other universal digraph models, the \emph{empty}\index{EmptyDigraph@\texttt{EmptyDigraph} class} and the \emph{indeterminate} digraph\index{IndeterminateDigraph@\texttt{IndeterminateDigraph} class}. 
\begin{lstlisting}[caption={The prekernels of the empty or indeterminate digraph},label=list:17.4]
>>> from digraphs import EmptyDigraph
>>> ed = EmptyDigraph(order=5)
>>> ed.showPreKernels()
  *--- Computing preKernels ---*
   Dominant kernel :
    ['1', '2', '3', '4', '5'] §\label{line:17.4.6}§
       independence :  1.0 
       dominance    :  1.0
       absorbency   :  1.0
   Absorbent kernel :
    ['1', '2', '3', '4', '5'] §\label{line:17.4.11}§
       independence :  1.0 
       dominance    :  1.0
       absorbency   :  1.0
>>> from digraphs import IndeterminateDigraph
>>> id = IndeterminateDigraph(order=5)
>>> id.showPreKernels()
  *--- Computing preKernels ---*
    Dominant prekernel :
    ['1', '2', '3', '4', '5'] §\label{line:17.4.20}§
       independence :  0.0    §\label{line:17.4.21}§
       dominance    :  1.0
       absorbency   :  1.0
    Absorbent prekernel :
    ['1', '2', '3', '4', '5'] §\label{line:17.4.25}§
       independence :  0.0    §\label{line:17.4.26}§
       dominance    :  1.0
       absorbency   :  1.0
\end{lstlisting}

In the empty digraph, the whole set of nodes gives indeed at the same time the unique initial and terminal prekernel (see Lines~\ref{line:17.4.6} and \ref{line:17.4.11}). Similarly, for the \emph{indeterminate} digraph (see Lines~\ref{line:17.4.20} and \ref{line:17.4.25}).

Both these results make sense, as in a completely empty or indeterminate digraph, there is no \emph{interior} of the digraph defined, only a \emph{border} which is hence at the same time an initial and terminal prekernel (see Sec.~\ref{sec:2.4}).  Notice however, that in the latter indeterminate case, the complete set of nodes verifies only weakly the internal stability condition (see Lines~\ref{line:17.4.21} and \ref{line:17.4.26}).

Other common digraph models, although being clearly oriented, may show nevertheless no apparent laterality, like \emph{chordless circuits}\index{chordless circuits}, i.e. holes surrounded by an oriented cycle -a circuit- of odd length. They do not admit in fact any initial or terminal prekernel.\index{CirculantDigraph@\texttt{CirculantDigraph} class}
\begin{lstlisting}[caption={The prekernels of the 5-circuit digraph},label=list:17.5]
>>> from digraphs import CirculantDigraph
>>> c5 = CirculantDigraph(order=5,circulants=[1])
>>> c5.showPreKernels()
  *----- statistics -----
   digraph name:  c5
   number of solutions
    dominant prekernels :  0
    absorbent prekernels:  0
\end{lstlisting}

Chordless circuits of \emph{even} length $2 \times k$, with $k > 1$, contain however two isomorphic prekernels of cardinality $k$ which qualify conjointly as initial and terminal candidates.
\begin{lstlisting}[caption={The prekernels of the 6-circuit digraph},label=list:17.6]
>>> c6 = CirculantDigraph(order=6,circulants=[1])
>>> c6.showPreKernels()
  *--- Computing preKernels ---*
    Dominant preKernels :
    ['1', '3', '5'] ind. : 1.0, dom. : 1.0, abs. : 1.0
    ['2', '4', '6'] ind. : 1.0, dom. : 1.0, abs. : 1.0
    Absorbent preKernels :
    ['1', '3', '5'] ind. : 1.0, dom. : 1.0, abs. : 1.0
    ['2', '4', '6'] ind. : 1.0, dom. : 1.0, abs. : 1.0
\end{lstlisting}

Chordless circuits of even length may thus be indifferently oriented along two opposite directions. Notice by the way in Fig.~\vref{fig:17.2} that the duals of all chordless circuits of odd or even length, i.e. \emph{filled} circuits\index{filled circuits} also called \emph{anti-holes}\index{anti-holes} (see Fig.~\vref{fig:17.3}), never contain any potential prekernel candidates.\index{DualDigraph@\texttt{DualDigraph} class}
\begin{lstlisting}[caption={The prekernels of the dual of the 6-circuit digraph},label=list:17.7]
>>> dc6 = -c6   # dc6 = DualDigraph(c6)
>>> dc6.showPreKernels()
  *----- statistics -----
    graph name:  dual_c6
    number of solutions
     dominant prekernels :  0
     absorbent prekernels:  0
>>> dc6.exportGraphViz(fileName='dualChordlessCircuit')
  *---- exporting a dot file for GraphViz tools ----*
    Exporting to dualChordlessCircuit.dot
    circo -Tpng dualChordlessCircuit.dot\
               -o dualChordlessCircuit.png
\end{lstlisting}
\begin{figure}[ht]
\sidecaption[t]
\includegraphics[width=7cm]{Figures/17-2-dualChordlessCircuit.pdf}
\caption[The dual of the chordless 6-circuit]{\emph{The dual of the chordless 6-circuit}. No initial or terminal prekernel --weakly independent and dominant, resp. absorbent subset of nodes-- may be found in this kind of digraphs}
\label{fig:17.2}       % Give a unique label
\end{figure}

We call \emph{weak}, a chordless circuit with indeterminate inner part.

In Listing~\vref{list:17.8} we use the \texttt{IndeterminateInnerPart} parameter\index{IndeterminateInnerPart@\texttt{IndeterminateInnerPart} parameter} of the \texttt{Cir\-culantDigraph} class for constructing such a weak chordless 6-circuit digraph. It is worth noticing in Fig.~\vref{fig:17.3} that the \emph{dual} version of a weak circuit corresponds to its \emph{converse} version \footnote{Not to be confused with the dual graph of a plane graph $g$ that has a vertex for each face of $g$. Here we mean the l\emph{ess than} (strict converse) relation corresponding to a \emph{greater or equal} relation, or the \emph{less than or equal} relation corresponding to a (strict converse) \emph{greater than} relation.}.
\begin{lstlisting}[caption={The weak 6-circuit digraph},label=list:17.8]
>>> from digraphs import CirculantDigraph
>>> c6 = CirculantDigraph(order=6,circulants=[1],\
...                  IndeterminateInnerPart=True)
>>> (-c6).exportGraphViz()
  *---- exporting a dot file for GraphViz tools ---------*
   Exporting to dual_c6.dot
   circo -Tpng dual_c6.dot -o dual-c6.png
>>> (~c6).exportGraphViz()
  *---- exporting a dot file for GraphViz tools ---------*
   Exporting to converse_c6.dot
   circo -Tpng converse_c6.dot -o converse-c6.png 
\end{lstlisting}
\begin{figure}[ht]
  % \sidecaption
  Dual of weak 6-circuit \hfill Converse of weak 6-circuit\\
  \includegraphics[height=6cm]{Figures/17-3-dual-c6.pdf}\hfill
  \includegraphics[height=6cm]{Figures/17-3-converse-c6.pdf}
\caption[Dual and converse transforms of the weak 6-circuit]{Dual and converse transforms of the weak 6-circuit give the same digraph}
\label{fig:17.3}       % Give a unique label
\end{figure}

Weak chordless circuits of length $n$ are in fact part of the class of digraphs that are invariant under the \emph{codual} transform, $cn = - (\sim cn) = \sim (-cn )$ \footnote{The class of \emph{self-codual} bipolar-valued digraphs consists of all weakly asymmetric digraphs, i.e. digraphs containing only asymmetric and/or indeterminate links. Limit cases consists of, on the one side, full tournaments with indeterminate reflexive links, and, on the other side, fully indeterminate digraphs. In this class, the converse (inverse $\sim$) operator is indeed identical to the dual (negation $-$ ) one.}. When digraph $cn$ is a weak chordless n-circuit, $cn$, $-cn$, $\sim cn$ and $\sim (-cn)$ will all admit the same set of prekernels.  

\section{Kernels in lateralised digraphs}
\label{sec:17.3}

Humans do live in an apparent physical space of plain transitive lateral orientation, fully empowered in finite geometrical 3D models with linear orders, where first, resp. last ranked, nodes deliver unique initial, resp. terminal, kernels. Similarly, in finite preorders, the first, resp. last, equivalence classes deliver the unique initial, resp. unique terminal, kernels. More generally, in finite partial orders, i.e. asymmetric and transitive digraphs, topological sort algorithms will easily reveal on the first, resp. last, level all unique initial, resp. terminal, kernels.

In genuine random digraphs, however, we may need to check for each of its MISs, whether one, both, or none of the lateralised external stability conditions may be satisfied. Consider, for instance in Listing~\vref{list:17.9}, the following random digraph instance of order 7 and generated with an arc probability of $30\%$. 
\begin{lstlisting}[caption={Generating a random digraph \texttt{rd} of order 7 and arc probability 0.3},label=list:17.9]
>>> from randomDigraphs import RandomDigraph
>>> rd = RandomDigraph(order=7,arcProbability=0.3,seed=5)
>>> rd.exportGraphViz('randomLaterality')
  *---- exporting a dot file for GraphViz tools ---*
   Exporting to randomLaterality.dot
   dot -Grankdir=BT -Tpng randomLaterality.dot\
                    -o randomLaterality.png
\end{lstlisting}
\begin{figure}[ht]
\sidecaption[t]
\includegraphics[width=5cm]{Figures/17-4-randomLaterality.pdf}
\caption[A random digraph of order 7 and arc probability $0.3$]{\emph{A random digraph instance of order 7 and arc probability} $0.3$. The digraph instance is neither asymmetric (\texttt{a3} $\Leftrightarrow$ \texttt{a6}) nor symmetric (\texttt{a2} $\rightarrow$ \texttt{a1}, \texttt{a1} $\not\rightarrow$ \texttt{a2}) and, the digraph is not transitive (\texttt{a5} $\rightarrow$ \texttt{a2} $\rightarrow$ \texttt{a1}, but \texttt{a5} $\not\rightarrow$ \texttt{a1})} 
\label{fig:17.4}       % Give a unique label
\end{figure}

The random digraph shown in Figure~\vref{fig:17.4} has no apparent special properties, except from being connected (see Line~\ref{line:17.10.3} in List.~\vref{list:17.10}).
\begin{lstlisting}[caption={Inspecting the properties of random digraph \texttt{rd}},label=list:17.10]
>>> rd.showComponents()
  *--- Connected Components ---*
  1: ['a1', 'a2', 'a3', 'a4', 'a5', 'a6', 'a7'] §\label{line:17.10.3}§
>>> rd.computeSymmetryDegree(Comments=True)
  Symmetry degree (%) of digraph <randomDigraph>:
   arcs x>y: 14, symmetric: 1, asymmetric: 13
   symmetric/arcs =  0.071
>>> rd.computeChordlessCircuits()
  []  # no chordless circuits detected §\label{line:17.10.9}§
>>> rd.computeTransitivityDegree(Comments=True)
  Transitivity degree (%) of graph <randomDigraph>:
   triples x>y>z: 23, closed: 11, open: 12
   closed/triples =  0.478 §\label{line:17.10.13}§
\end{lstlisting}

There are no chordless circuits (see Line~\ref{line:17.10.9} above) and more than half of the required transitive closure is missing (see Line~\ref{line:17.10.13} above).

Now, we know that its potential prekernels must be among its set of maximal independent choices. 
\begin{lstlisting}[caption={Inspecting the prekernels of random digraph \texttt{rd}},label=list:17.11]
>>> rd.showMIS()
  *---  Maximal independent choices ---*
    ['a2', 'a4', 'a6']
    ['a6', 'a1']
    ['a5', 'a1']
    ['a3', 'a1']
    ['a4', 'a3']
    ['a7']
>>> rd.showPreKernels()
  *--- Computing preKernels ---*
   Dominant preKernels :
    ['a2', 'a4', 'a6']
       independence :  1.0
       dominance    :  1.0
       absorbency   :  -1.0
       covering     :  0.500 §\label{line:17.11.16}§
    ['a4', 'a3']
       independence :  1.0
       dominance    :  1.0
       absorbency   :  -1.0
       covering     :  0.600 §\label{line:17.11.21}§
   Absorbent preKernels :
    ['a3', 'a1']
       independence :  1.0
       dominance    :  -1.0
       absorbency   :  1.0
       covering     :  0.500 §\label{line:17.11.27}§
    ['a6', 'a1']
       independence :  1.0
       dominance    :  -1.0
       absorbency   :  1.0
       covering     :  0.600 §\label{line:17.11.32}§
\end{lstlisting}
     
Among the six MISs contained in random digraph \texttt{rd} we discover in Listing~\vref{list:17.11} two initial and two terminal prekernels. Notice by the way the covering values (between $0.0$ and $1.0$) shown by the \texttt{showPreKernels()}\index{showPreKernels@\texttt{showPreKernels()}} method (Lines \ref{line:17.11.16}, \ref{line:17.11.21}, \ref{line:17.11.27} and \ref{line:17.11.32}). The higher this value, the more the corresponding prekernel candidate makes apparent the digraph's laterality. In Fig.~\vref{fig:17.5}, the same digraph \texttt{rd} is redrawn by looking into its interior via the best covering initial prekernel candidate: the dominant choice \{\texttt{a3}, \texttt{a4}\} (coloured in yellow), and looking out of it via the best covered terminal prekernel candidate: the absorbent choice \{\texttt{a1}, \texttt{a6}\} (coloured in blue).
\begin{lstlisting}
>>> rd.exportGraphViz(fileName='orientedLaterality',\
...                   firstChoice=set(['a3', 'a4']),\
...                   lastChoice=set(['a1', 'a6']))
  *---- exporting a dot file for GraphViz tools ----*
   Exporting to orientedLaterality.dot
   dot -Grankdir=BT -Tpng orientedLaterality.dot\
                    -o orientedLaterality.png
\end{lstlisting}
\begin{figure}[ht]
\sidecaption[t]
\includegraphics[width=6cm]{Figures/17-5-orientedLaterality.pdf}
\caption[Oriented drawing of a digraph]{A random digraph oriented by best covering initial and best covered terminal prekernels}
\label{fig:17.5}       % Give a unique label
\end{figure}

As all reasonable bipolar-valued outranking digraph usually show some laterality --the marginal criteria preferences being not all totally contradictory-- initial and terminal prekernels provide convincing first, resp. last, choice recommendations as illustrated in Chapter~\vref{sec:4}.

\section{Computing first and last choice recommendations}
\label{sec:17.4}

To illustrate this idea, let us finally compute in Listing~\vref{list:17.12} first and last choice recommendations in a random bipolar-valued outranking digraph.
\begin{lstlisting}[caption={Generating a random bipolar-valued outranking digraph},label=list:17.12]
>>> from outrankingDigraphs import\
...                RandomBipolarOutrankingDigraph
>>> g = RandomBipolarOutrankingDigraph(seed=5)
>>> g
  *------- Object instance description ------*
   Instance class   : RandomBipolarOutrankingDigraph
   Instance name    : randomOutranking
   Actions          : 7
   Criteria         : 7
   Size             : 26
   Determinateness  : 34.275
   Valuation domain : {'min': -100.0, 'med': 0.0, 'max': 100.0}
>>> g.showHTMLPerformanceTableau()
\end{lstlisting}
\begin{figure}[ht]
%\sidecaption
\includegraphics[width=10cm]{Figures/17-6-randomOutranking.png}
\caption{The performance tableau of a random outranking digraph instance}
\label{fig:17.6}       % Give a unique label
\end{figure}

The associated random performance tableau shown in Fig.~\vref{fig:17.6} reveals the performance evaluations of 7 potential decision alternatives with respect to 7 decision criteria supporting each an increasing performance scale from $0.0$ to $100.0$. Notice the missing performance data concerning decision alternatives \texttt{a2} and \texttt{a5}. The resulting \emph{strict} outranking - i.e. a weighted majority supported --\emph{``better than without considerable counter-performance''}-- digraph is shown in Fig.~\vref{fig:17.7}.
\begin{lstlisting}
>>> gcd = ~(-g)  # Codual: the converse of the negation
>>> gcd.exportGraphViz(fileName='tutOutRanking')
  *---- exporting a dot file for GraphViz tools ----*
   Exporting to tutOutranking.dot
   dot -Grankdir=BT -Tpng tutOutranking.dot\
                    -o tutOutranking.png\end{lstlisting}
\begin{figure}[ht]
\sidecaption[t]
\includegraphics[width=7cm]{Figures/17-7-tutOutranking.pdf}
\caption[A random strict outranking digraph instance]{\emph{A random strict outranking digraph instance}. All decision alternatives appear strictly better performing than alternative \texttt{a7}. We call it a \Condorcet loser and it is an evident terminal prekernel candidate. On the other side, three alternatives: \texttt{a1}, \texttt{a2} and \texttt{a4} are not dominated. They give together an initial prekernel candidate}
\label{fig:17.7}       % Give a unique label
\end{figure}

\begin{lstlisting}[caption={Computing the prekernels of the strict outranking digraph \texttt{gcd}},label=list:17.13]
>>> gcd.showPreKernels()
  *--- Computing preKernels ---*
   Dominant preKernels :
    ['a1', 'a2', 'a4']   §\label{line:17.13.4}§
       independence :  0.00
       dominance    :  6.98
       absorbency   :  -48.84
       covering     :  0.667
   Absorbent preKernels :
    ['a3', 'a7']   §\label{line:17.13.10}§
       independence :  0.00
       dominance    :  -74.42
       absorbency   :  16.28
       covered      :  0.800
\end{lstlisting}

With such unique disjoint initial and terminal prekernels (see Line~\ref{line:17.13.4} and ~\ref{line:17.13.10} in List.~\vref{list:17.13}), the random digraph \texttt{gcd} is hence clearly lateralised. Indeed, these initial and terminal prekernels of the codual outranking digraph reveal \emph{first}, resp. \emph{last}, choice recommendations one may formulate on the basis of a given outranking digraph instance.
\begin{lstlisting}[caption={Computing a first and last choice recommendation from digraph \texttt{gcd}},label=list:17.14]
>>> g.showBestChoiceRecommendation()
  Rubis best choice recommendation(s) (BCR)
   (in decreasing order of determinateness)   
   Credibility domain: [-100.00,100.00]
   === >> potential first choice(s)
    * choice              : ['a1', 'a2', 'a4']
      independence        : 0.00
      dominance           : 6.98
      absorbency          : -48.84
      covering (%)        : 66.67
      determinateness (%) : 57.97
      - most credible action(s) =
                      {'a4': 20.93,'a2': 20.93}  §\label{line:17.14.13}§
   === >> potential last choice(s) 
    * choice              : ['a3', 'a7']
      independence        : 0.00
      dominance           : -74.42
      absorbency          : 16.28
      covered (%)         : 80.00
      determinateness (%) : 64.62
      - most credible action(s) = { 'a7': 48.84, } §\label{line:17.14.21}§
\end{lstlisting}

Notice in Lines~\ref{line:17.14.13} and \ref{line:17.14.21} in Listing~\vref{list:17.14} that solving the valued kernel equation system provides furthermore a positive characterisation of the most credible decision alternatives in each respective choice recommendation. Alternatives \texttt{a2} and \texttt{a4} give equivalent candidates for a unique \emph{first} choice, and alternative \texttt{a7} is clearly confirmed as the \emph{last} choice.

In Fig.~\vref{fig:17.8}, we orient the drawing of the strict outranking digraph instance with the help of these first and last choice recommendations. 
\begin{lstlisting}
>>> gcd.exportGraphViz(fileName='firstLastOrientation',\
...                    firstChoice=['a2','a4'],\
...                    lastChoice=['a7'])
  *---- exporting a dot file for GraphViz tools -----*
   Exporting to firstLastOrientation.dot
   dot -Grankdir=BT -Tpng firstLastOrientation.dot\
                    -o firstLastOrientation.png
\end{lstlisting}
\begin{figure}[ht]
\sidecaption[t]
\includegraphics[width=7cm]{Figures/17-8-bestWorstOrientation.pdf}
\caption[The strict outranking digraph oriented by its first and last choice recommendations]{\emph{The strict outranking digraph oriented by its first and last choice recommendations}. The gray arrows, like the one between alternatives \texttt{a4} and \texttt{a1}, represent indeterminate preferential situations. Alternative \texttt{a1} appears hence to be rather incomparable to all the other, except alternative \texttt{a7}}
\label{fig:17.8}       % Give a unique label
\end{figure}

It may be interesting to compare this result with a \Copeland ranking of the underlying performance tableau (see Sec.~\ref{sec:8.2} on ranking with incommensurable criteria).
\begin{lstlisting}
>>> g.showHTMLPerformanceHeatmap(colorLevels=5, ndigits=0,\
...             Correlations=True, rankingRule='Copeland')
\end{lstlisting}
\begin{figure}[ht]
%\sidecaption
\includegraphics[width=10cm]{Figures/17-9-outRankingResult.png}
\caption{Heat map with Copeland ranking of the performance tableau}
\label{fig:17.9}       % Give a unique label
\end{figure}

In the resulting linear ranking (see Fig.~\vref{fig:17.9}), alternative \texttt{a4} is set at first rank, followed by alternative \texttt{a2}. This makes sense as alternative \texttt{a4} shows three performances in the first quintile, whereas \texttt{a2} is only partially evaluated and shows only two such excellent performances. But \texttt{a4} also shows a very weak performance in the first quintile. Both decision actions, hence, don't show eventually a performance profile that would make apparent a clear preference situation in favour of one or the other. In this sense, the prekernels based best choice recommendations may appear more faithful with respect to the actually definite strict outranking relation than any '\emph{forced}' linear ranking result as shown in Fig.~\vref{fig:17.9}.

\section{Tractability of kernel computation}
\label{sec:17.5}

Let us give some hints on the \emph{tractability} of prekernel computations. Detecting all prekernels in a digraph is a computationally difficult problem. Checking external stability conditions for an independent choice is equivalent to checking its maximality and may be done in the linear complexity of the order of the digraph. However, checking all independent choices contained in a digraph may get hard already for tiny sparse digraphs of order $n > 20$ \citep{BIS-2006b}. Indeed, the worst case is given by an empty or indeterminate digraph where the set of all potential independent choices to check is in fact the power set of the vertices.
\begin{lstlisting}
>>> from digraphs import EmptyDigraph
>>> e = EmptyDigraph(order=20)
>>> e.showMIS()   # by visiting all 2^20 independent choices
  *---  Maximal independent choices ---*
    [ '1', '2', '3', '4', '5', '6', '7', '8', '9','10',
     '11','12','13','14','15','16','17','18','19','20']
    number of solutions:  1
    execution time: 1.47640 sec.  # <----- 
>>> 2**20
  1048576
\end{lstlisting}

Now, there exist more efficient specialised algorithms for directly enumerating MISs and dominant or absorbent kernels contained in specific digraph models without visiting all independent choices \citep{BIS-2006b}. \emph{Alain Hertz}\index{Hertz@\emph{A. Hertz}} provided kindly such a MISs enumeration algorithm for the \Digraph project (the \texttt{showMIS\_AH()} method)\index{showMISAH@\texttt{showMIS\_AH}()}. When the number of independent choices is big compared to the actual number of MISs, like in very sparse or empty digraphs, the performance difference may be dramatic (see Line 8 above and Line~\ref{line:17.15.16} below).
\begin{lstlisting}[caption={Enumerating MISs by visiting only maximal independent choices (\emph{A. Hertz}) },label=list:17.15]
>>> e.showMIS_AH()
  # by visiting only maximal independent choices
  *-----------------------------------*
  * Python implementation of Hertz's  *
  * algorithm for generating all MISs *
  * R.B. version 7(6)-25-Apr-2006     *
  *-----------------------------------*
  ===>>> Initial solution :
  [ '1','2','3','4','5','6','7','8','9','10','11',
    '12','13','14','15','16','17','18','19','20']
  *---- results ----*
  [ '1','2','3','4','5','6','7','8','9','10','11',
    '12','13','14','15','16','17','18','19','20']
  *---- statistics ----*
  MIS solutions    :  1
  execution time   : 0.00026 sec. # <---- §\label{line:17.15.16}§
  iteration history:  1
\end{lstlisting}

For more or less dense strict outranking digraphs of modest order, as facing usually in MCDA applications, enumerating all independent choices remains however in most cases tractable, especially by using a very efficient iterator generator with the \texttt{independentChoices()} method shown in Listing~\vref{list:17.16}\index{independentChoices@\texttt{independentChoices}()}.
\begin{lstlisting}[caption={Generating all independent choices in a digraph},label=list:17.16]
def independentChoices(self,U):
    """
    Generator for all independent choices with associated
    dominated, absorbed and independent neighborhoods
    of digraph instance self.
    Initiate with U = self.singletons().
    Yields [(independent choice, domnb, absnb, indnb)].
    """
    if U == []:
        yield [(frozenset(),set(),set(),set(self.actions))]
    else:
        x = list(U.pop())
        for S in self.independentChoices(U):
            yield S
            if x[0] <=  S[0][3]:
                Sxgamdom = S[0][1] | x[1]
                Sxgamabs = S[0][2] | x[2]
                Sxindep = S[0][3] &  x[3]
                Sxchoice = S[0][0] | x[0]
                Sx = [(Sxchoice,Sxgamdom,Sxgamabs,Sxindep)]
                yield Sx
\end{lstlisting}

And, checking maximality of independent choices via the external stability conditions during their enumeration with the \texttt{computePreKernels()} method shown in Listing~\vref{list:17.17} provides the effective advantage of computing all initial and terminal prekernels in a single loop (see Line~\ref{line:17.17.10} and \citealp{BIS-2006b}).
\begin{lstlisting}[caption={Computing dominant and absorbent preKernels},label=list:17.17]
def computePreKernels(self):
    """
    computing dominant and absorbent preKernels:
    Result in self.dompreKernels and self.abspreKernels
    """
    actions = set(self.actions)
    n = len(actions)
    dompreKernels = set()
    abspreKernels = set()
    for choice in self.independentChoices(self.singletons()): §\label{line:17.17.10}§
        restactions = actions - choice[0][0]
        if restactions <= choice[0][1]:
            dompreKernels.add(choice[0][0])
        if restactions <= choice[0][2]:
            abspreKernels.add(choice[0][0])
    self.dompreKernels = dompreKernels
    self.abspreKernels = abspreKernels
\end{lstlisting}
 
Finally, we use our bipolar-valued epistemic logic framework for computing the credibility that an individual node of the digraph fits with being a member of an initial or terminal prekernel. For this purpose we use kernel equation systems \citep*{SCH-1985}.

\section{Solving kernel equation systems}
\label{sec:17.6}

Let $G(X,R)$ be a crisp irreflexive digraph defined on a finite set $X$ of nodes and where $R$ is the corresponding $\{-1,+1\}$-valued adjacency matrix. Let $Y$ be the $\{-1,+1\}$-valued membership characteristic (row) vector of a choice in $X$.

When $Y$ satisfies the following equation system:
\begin{equation}\label{eq:17.1}
  Y \circ R \; = \; -Y\;,
\end{equation}
where for all $x$ in $X$,
\begin{equation}\label{eq:17.2}
     (Y \circ R)(x) \; = \; \max_{y \in X, x \neq y} \big ( \min(Y(x), R(x,y))\big)\;,`
\end{equation}
then $Y$ characterises an \emph{initial kernel} \citep*{BIS-2006a,BIS-2006b}.

When transposing now the membership characteristic vector $Y$ into a column vector $Y^t$, the following equation system: $R \circ Y^t \; = \; -Y^t$.
makes $Y^t$ similarly characterise a \emph{terminal kernel}.

Let us verify this result in Listing~\vref{list:17.18} on a tiny random digraph.
\begin{lstlisting}[caption={Verifying the kernel equation system on a tiny random digraph},label=list:17.18]
>>> from digraphs import RandomDigraph
>>> g = RandomDigraph(order=3,seed=1)
>>> g.showRelationTable()
  * ---- Relation Table -----
     R  | 'a1'  'a2'  'a3'	  
  ------|---------------------
   'a1' |  -1    +1    -1	 
   'a2' |  -1    -1    +1	 
   'a3' |  +1    +1    -1	 
>>> g.showPreKernels()
  *--- Computing preKernels ---*
   Dominant preKernels :
    ['a3']
   Absorbent preKernels :
    ['a2']
\end{lstlisting}

It is easy to verify by hand that the characteristic vector $[-1, -1, +1]$ satisfies the initial kernel equation system; node \texttt{a3} gives an \emph{initial} kernel. Similarly, the characteristic vector $[-1, +1, -1]$ verifies indeed the terminal kernel equation system and node \texttt{a2} gives hence a \emph{terminal} kernel.

We succeeded now in generalising crisp kernel equation systems to genuine bipolar-valued digraphs \citep*{BIS-2006a,BIS-2006b}. The constructive proof, found by \emph{Marc Pirlot}\index{Pirlot@\textsl{M. Pirlot}}, is based on the following \emph{fixpoint equation} that may be used for computing bipolar-valued kernel membership vectors:
\begin{equation}\label{eq:17.4}
T(Y) \; := \; -(Y \circ R) = Y\;.
\end{equation}
\emph{John von Neumann}\index{Neumann@\textsl{J. von Neumann}} showed indeed that, when a digraph $G(X,R)$ is acyclic with a unique initial kernel $K$ characterised by its membership characteristics vector $Y_k$, then the following double fixpoint equation:
\begin{equation}\label{eq:17.5}
T^2(Y) \; := \; -\big( -(Y \circ R) \circ R) \; = \; Y\;,
\end{equation}
will admit a stable \emph{high} and a stable \emph{low} fixpoint solution that converge both to $Y_k$ \citep{SCH-1985}.

Inspired by the crisp double fixpoint equation~\vref{eq:17.5}, we observed that for a given bipolar-valued digraph $G(X,R)$, each one of its dominant or absorbent prekernels $K_i$ in $X$ determines an induced partial digraph $G(X,R/K_i)$ which is acyclic and admits $K_i$ as unique prekernel \citep{BIS-1997}.

Following the \emph{von Neumann} fixpoint algorithm, a similar bipolar-valued extended double fixpoint algorithm, applied to $G(X,R/K_i)$, allows us to compute the associated bipolar-valued kernel characteristic vectors $Y_i$ in polynomial complexity.

\begin{algorithm}[H]
  {\normalsize
\begin{itemize}
 \item [] \emph{in} : bipolar-valued digraph $G(X,R)$,
 \item [] \emph{out} : set $\{Y_1, Y_2, .. \}$ of bipolar-valued kernel membership characteristic vectors.
\end{itemize}
\begin{enumerate}
\item Enumerate all initial and terminal prekernels $K_1$, $K_2$, ... in the given bipolar-valued digraph (see List.~\vref{list:17.17});
\item For each crisp initial kernel $K_i$:
  \begin{enumerate}
  \item Construct a partially determined subgraph $G(X,R/K_i)$ supporting exactly this unique initial kernel $K_i$;
  \item Use the double fixpoint equation $T^2$ (Eq.~\ref{eq:17.5}) with the partially determined adjacency matrix $R/K_i$ for computing a stable low and a stable high fixpoint;
   \item \label{step:2.c} Determine the bipolar-valued $K_i$-membership characteristic vector $Y_i$ with an epistemic disjunction of the previous low and high fixpoints;
  \end{enumerate}
\item Repeat step (2) for each terminal kernel $K_j$ by using the double fixpoint equation $T^2$ with the transpose of the adjacency matrix $R/K_j$.
\end{enumerate}
}
\caption{Computing bipolar-valued kernel characteristic vectors}
\label{alg:17.1}
\end{algorithm}

\paragraph{\textbf{Time for a practical illustration}}

\noindent We reconsider the random digraph \texttt{g} generated in Listing~\vref{list:17.12}. Digraph \texttt{g} models the pairwise outranking situations between seven decision alternatives evaluated on seven incommensurable performance criteria. We recompute its corresponding bipolar-valued prekernels on the associated codual digraph \texttt{gcd}.
\begin{lstlisting}
>>> gcd = ~(-g) # strict outranking digraph
>>> gcd.showPreKernels()
  *--- Computing prekernels ---*
   Dominant prekernels :
    ['a1', 'a4', 'a2']
       independence :  +0.000
       dominance    :  +0.070
       absorbency   :  -0.488
       covering     :  +0.667
   Absorbent prekernels :
    ['a7', 'a3']
       independence :  +0.000
       dominance    :  -0.744
       absorbency   :  +0.163
       covered      :  +0.800
  *----- statistics -----
   graph name:  converse-dual_rel_randomperftab
   number of solutions
    dominant kernels :  1
    absorbent kernels:  1
   cardinality frequency distributions
    cardinality     :  [0, 1, 2, 3, 4, 5, 6, 7]
    dominant kernel :  [0, 0, 0, 1, 0, 0, 0, 0]
    absorbent kernel:  [0, 0, 1, 0, 0, 0, 0, 0]
   Execution time  : 0.00022 sec.
\end{lstlisting}

The codual outranking digraph \texttt{gcd}, modelling a strict outranking relation, admits an initial prekernel $\{\mathtt{a1}, \mathtt{a2}, \mathtt{a4}\}$ and a terminal one $\{\mathtt{a3}, \mathtt{a7}\}$ (see Lines 5 and 11 above).

In Listing~\vref{list:17.19} we now compute, with the \texttt{domkernelrestrict()} method,\index{domkernelrestrict@\texttt{domkernelrestrict()}} the initial prekernel-restricted adjacency table (see Fig.~\vref{fig:17.10}).
\begin{lstlisting}[caption={Computing a dominant prekernel restricted adjancecy table},label=list:17.19]
>>> k1Relation = gcd.domkernelrestrict(['a1','a2','a4'])
>>> gcd.showHTMLRelationTable(\
...      actionsList=['a1','a2','a4','a3','a5','a6','a7'],\
...      relation=k1Relation,\
...      tableTitle='K1 restricted adjacency table')
\end{lstlisting}
\begin{figure}[ht]
\sidecaption[t]
\includegraphics[width=7cm]{Figures/17-10-k1restricted.png}
\caption[Initial kernel $\{\mathtt{a1}, \mathtt{a2}, \mathtt{a4}\}$ restricted adjacency table]{\emph{Initial kernel} $\mathtt{a1}, \mathtt{a2}, \mathtt{a4}\}$ \emph{restricted adjacency table}. The outranking situation between alternatives \texttt{a4} and \texttt{a1} being \emph{indeterminate}, this initial prekernel is only weakly independent. }
\label{fig:17.10}       % Give a unique label
\end{figure}

The corresponding initial prekernel membership characteristic vector may be computed with the \texttt{computeKernelVector()} method.\index{computeKernelVector@\texttt{computeKernelVector()}}
\begin{lstlisting}[caption={Fixpoint iterations for initial prekernel \texttt{\{a1, a2, a4\}}},label=list:17.20,basicstyle=\ttfamily\scriptsize]
>>> gcd.computeKernelVector(['a1','a2','a4'],\
...                 Initial=True,Comments=True)
 --> Initial prekernel: {'a1', 'a2', 'a4'}
 initial low vector : [-1.00,-1.00,-1.00,-1.00,-1.00,-1.00,-1.00]
 initial high vector: [+1.00,+1.00,+1.00,+1.00,+1.00,+1.00,+1.00]
 1st low vector     : [ 0.00,+0.21,-0.21, 0.00,-0.44,-0.07,-0.58]
 1st high vector    : [+1.00,+1.00,+1.00,+1.00,+1.00,+1.00,+1.00]
 2nd low vector     : [ 0.00,+0.21,-0.21, 0.00,-0.44,-0.07,-0.58]
 2nd high vector    : [ 0.00,+0.21,-0.21,+0.21,-0.21,-0.05,-0.21]
 3rd low vector     : [ 0.00,+0.21,-0.21,+0.21,-0.21,-0.07,-0.21]
 3rd high vector    : [ 0.00,+0.21,-0.21,+0.21,-0.21,-0.05,-0.21]
 4th low vector     : [ 0.00,+0.21,-0.21,+0.21,-0.21,-0.07,-0.21]
 4th high vector    : [ 0.00,+0.21,-0.21,+0.21,-0.21,-0.07,-0.21]
 Iterations         : 4
 low & high fusion  : [ 0.00,+0.21,-0.21,+0.21,-0.21,-0.07,-0.21]
 Choice vector for initial prekernel: {'a1', 'a2', 'a4'}
   'a2': +0.21
   'a4': +0.21
   'a1':  0.00
   'a6': -0.07
   'a3': -0.21
   'a5': -0.21
   'a7': -0.21
\end{lstlisting}

In Listing~\vref{list:17.20} we start the fixpoint computation with an empty set characterisation as first low vector and a complete set $X$ characterising high vector. After each iteration, the low vector is set to the negation of the previous high vector and the high vector is set to the negation of the previous low vector.

A unique stable prekernel characteristic vector $Y_1$ is here attained at the fourth iteration with positive members \texttt{a2}: $+0.21$ and \texttt{a4}: $+0.21$ ($60.5\%$ criteria significance majority); \texttt{a1}: $0.00$ being an ambiguous potential member. Alternatives \texttt{a3}, \texttt{a5}, \texttt{a6} and \texttt{a7} are all negative members, i.e. positive \emph{non members} of this outranking prekernel.

Let us also compute the restricted adjacency table for the outranked, i.e. the \emph{terminal} prekernel \{\texttt{a3}, \texttt{a7}\}.
\begin{lstlisting}
>>> k2Relation = gcd.abskernelrestrict(['a3','a7'])
>>> gcd.showHTMLRelationTable(\
...  actionsList=['a3','a7','a1','a2','a4','a5','a6'],\
...  relation=k2Relation,\
...  tableTitle='K2 restricted adjacency table')
\end{lstlisting}
\begin{figure}[ht]
\sidecaption[t]
\includegraphics[width=7cm]{Figures/17-11-k2restricted.png}
\caption[Terminal prekernel \{\texttt{a3}, \texttt{a7}\} restricted adjacency table]{\emph{Terminal prekernel} \{\texttt{a3}, \texttt{a7}\} \emph{restricted adjacency table}. Again, we notice that this terminal prekernel is only weakly independent.}
\label{fig:17.11}       % Give a unique label
\end{figure}

The corresponding bipolar-valued characteristic vector $Y_2$ may be computed as follows:
\begin{lstlisting}[basicstyle=\ttfamily\scriptsize]
>>> gcd.computeKernelVector(['a3','a7'],\
...                         Initial=False,Comments=True)
 --> Terminal prekernel: {'a3', 'a7'}
 initial low vector  : [-1.00,-1.00,-1.00,-1.00,-1.00,-1.00,-1.00]
 initial high vector : [+1.00,+1.00,+1.00,+1.00,+1.00,+1.00,+1.00]
 1st low vector      : [-0.16,-0.49, 0.00,-0.58,-0.16,-0.30,+0.49]
 1st high vector     : [+1.00,+1.00,+1.00,+1.00,+1.00,+1.00,+1.00]
 2nd low vector      : [-0.16,-0.49, 0.00,-0.58,-0.16,-0.30,+0.49]
 2nd high vector     : [-0.16,-0.49, 0.00,-0.49,-0.16,-0.26,+0.49]
 3rd low vector      : [-0.16,-0.49, 0.00,-0.49,-0.16,-0.26,+0.49]
 3rd high vector     : [-0.16,-0.49, 0.00,-0.49,-0.16,-0.26,+0.49]
 Iterations          : 3
 high & low fusion   : [-0.16,-0.49, 0.00,-0.49,-0.16,-0.26,+0.49]
 Choice vector for terminal prekernel: {'a3','a7'}
    'a7': +0.49 
    'a3':  0.00
    'a1': -0.16
    'a5': -0.16
    'a6': -0.26
    'a2': -0.49
    'a4': -0.49
\end{lstlisting}

A unique stable bipolar-valued high and low fixpoint is attained at the third iteration with alternative \texttt{a7} positively confirmed (about $(1.0+0.49)/2 = 0.75\%$ criteria significance majority, see Line 15 above) as member of this terminal prekernel, whereas the membership of alternative \texttt{a3} in this prekernel appears indeterminate. All the remaining nodes have negative membership characteristic values and are hence positively excluded from this prekernel.
\begin{figure}[ht]
\sidecaption[t]
\includegraphics[width=6cm]{Figures/17-12-bestWorstOrientation.pdf}
\caption[The strict outranking digraph oriented by its initial and terminal prekernels]{\emph{The strict outranking digraph oriented by its initial and terminal prekernels}. Notice the indeterminate outranking situation between alternatives \texttt{a4} and \texttt{a1}, and the same indeterminate outranking situation between alternatives \texttt{a3} and \texttt{a7}}
\label{fig:17.12}       % Give a unique label
\end{figure}

When we reconsider the graphviz drawing of this outranking digraph in Figure~\vref{fig:17.12}, it becomes obvious here why alternative \texttt{a1} is \emph{neither included nor excluded} from the initial prekernel. Same observation is applicable to alternative \texttt{a3} that can \emph{neither be included nor excluded} from the terminal prekernel. it may even happen, in case of more indeterminate outranking situations, that no alternative  is positively included or excluded from a weakly independent prekernel; the corresponding bipolar-valued membership characteristic vector being completely indeterminate.

To illustrate finally why sometimes it is necessary to operate an epistemic disjunctive fusion of unequal stable low and high membership characteristics vectors (see Alg.~\vref{alg:17.1}, Step~\ref{step:2.c}), let us consider, for instance, the following crisp \texttt{7}-cycle graph.
\begin{lstlisting}
>>> from digraphs import CirculantDigraph
>>> c7 = CirculantDigraph(order=7,circulants=[-1,1])
>>> c7			     
  *------- Digraph instance description ------*
   Instance class      : CirculantDigraph
   Instance name       : c7
   Digraph Order       : 7
   Digraph Size        : 14
   Valuation domain    : [-1.00;1.00]
   Determinateness (%) : 100.00
   Attributes          : ['name','order','circulants',
                          'actions','valuationdomain',
                          'relation','gamma','notGamma']
\end{lstlisting}		       

Digraph \texttt{c7} is a symmetric crisp digraph showing, among others, the maximal independent set \{\texttt{2},\texttt{5},\texttt{7}\}, i.e. an initial as well as terminal kernel. The \texttt{computeKer\-nelVector()} method\index{computeKernelVector@\texttt{computeKernelVector()}} computes the corresponding initial kernel characteristic vector.
\begin{lstlisting}[basicstyle=\ttfamily\scriptsize]
>>> c7.computeKernelVector(['2','5','7'],\
...                       Initial=True,Comments=True)
 --> Initial kernel: {'2', '5', '7'}
 initial low vector  : [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0]
 initial high vector : [+1.0, +1.0, +1.0, +1.0, +1.0, +1.0, +1.0]
 1 st low vector     : [-1.0,  0.0, -1.0, -1.0,  0.0, -1.0,  0.0]
 1 st high vector    : [+1.0, +1.0, +1.0, +1.0, +1.0, +1.0, +1.0]
 2 nd low vector     : [-1.0,  0.0, -1.0, -1.0,  0.0, -1.0,  0.0]
 2 nd high vector    : [ 0.0, +1.0,  0.0,  0.0, +1.0,  0.0, +1.0]
 stable low vector   : [-1.0,  0.0, -1.0, -1.0,  0.0, -1.0,  0.0]
 stable high vector  : [ 0.0, +1.0,  0.0,  0.0, +1.0,  0.0, +1.0]
 Iterations          : 3
 low & high fusion   : [-1.0, +1.0, -1.0, -1.0, +1.0, -1.0, +1.0]
 Choice vector for initial prekernel: {'2', '5', '7'}
    '7': +1.00
    '5': +1.00
    '2': +1.00
    '6': -1.00
    '4': -1.00
    '3': -1.00
    '1': -1.00
\end{lstlisting}

Notice that the stable low vector characterises the \emph{negative membership} part, whereas, the stable high vector characterises the \emph{positive membership} part (see Lines 10-11 above).The bipolar epistemic fusion assembles eventually both stable parts into the correct prekernel characteristic vector (Line 13). 

The adjacency matrix of a symmetric digraph staying \emph{unchanged} by the transposition operator, the previous computations, when qualifying the same kernel as a terminal instance, will hence produce exactly the same result.

It is worthwhile noticing the essential computational role, the logical indeterminate value $0.0$ is playing in this double fixpoint algorithm. To implement such kind of algorithms without a logical \emph{neutral} term would be like implementing numerical algorithms without a possible usage of the number $0$. Infinitely many trivial impossibility theorems and dubious logical results come up. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\phantomsection
\addcontentsline{toc}{section}{Notes}
\section*{Notes}

Following the observation that an independent absorbent choice in an acyclic digraph corresponds to the zero values of the associated \Grundy function, \citet{RIG-1948} introduced the name ``noyau'' (kernel) for such a choice. Terminal kernels where in the sequel studied by \citet{BER-1958} in the context of Combinatorial Game Theory. Initial kernels --independent and dominating choices-- were introduced under the name game solutions by \citet{NEU-1944}. The absorbent version of the crisp kernel equation system~\vref{eq:17.1} was first introduced by \citet*{SCH-1985} in the context of their thorough exploration of relational algebra.

The fuzzy version of kernel equation systems was first investigated by \citet{KIT-1993}. Commenting on this work at a meeting in Spring 1995 of the EURO Working Group on Multicriteria Decision Aiding in Lausanne (Switzerland), \emph{Marc Roubens}\index{Roubens@\textsl{M. Roubens}} feared that solving such fuzzy kernel equation systems could be computationally difficult. Triggered by his pessimistic remark and knowing about kernel equation systems and the \Neumann fixpoint theorem \citep{NEU-1944,SCH-1985}, I immediately started to implement in Prolog a solver for the valued version of Equation~\vref{eq:17.1}; the equation system serving as constraints for a discrete labelling of all possible rational solution vectors. And in Summer 1995, we luckily obtained with a commercial finite domain solver the very first valued initial and terminal kernels from a didactic outranking digraph of order 8, well known in the multiple-criteria decision aiding community. The computation took several seconds on a CRAY 6412 superserver with 12 processors operating in a nowadays ridiculous CPU speed of 90 Mhz. The labelled solution vectors, obtained in the sequel for any outranking digraph with a single initial or terminal kernel, were structured in a way that suggested the converging stages of the \Neumann fixpoint algorithm and so gave the initial hint for Algorithm~\ref{alg:17.1} \citep*{BIS-1996,BIS-1997,BIS-2004d}. 

In our present Python3.9 implementation, such a tiny problem is solved in less than a thousandth of a second on a common laptop. And this remains practically the same for any relevant example of outranking digraph observed in a real decision-aiding problem. Several times we wrote in our personal journal that there is certainly now no more potential for any substantial improvement of this computational efficiency; Only to discover, shortly later, that following a new theoretical idea or choosing a more efficient implementation –-using for instance the amazing instrument of iterator generators in Python–-, execution times could well be divided by 20.

This nowadays available computational efficiency confers the bipolar-valued kernel concept a methodological premium for solving specific decision problems on the basis of the bipolar-valued outranking digraph (see Chap.~\ref{sec:4} and Chap.~\ref{sec:12}). But it also opens new opportunities for verifying and implementing kernel extraction algorithms for more graph theoretical purposes. New results, like enumerating the non isomorphic maximal independent sets --the kernels-- of known difficult graph instances like the $n$-cycle, could be obtained (see Sec.~\ref{sec:21.7} and \citealp*{ISO-2008}).

%%%%%%% The chapter bibliography
%\normallatexbib
%\clearpage
%\phantomsection
%\addcontentsline{toc}{section}{Chapter Bibliography}
%\input{02-mainMatters/17-chapterKernels.bbl}
\bibliographystyle{spbasic}
\bibliography{03-backMatters/reference}
